{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1aa1fa27",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-21T22:45:29.567200Z",
     "iopub.status.busy": "2023-08-21T22:45:29.566820Z",
     "iopub.status.idle": "2023-08-21T22:45:42.705189Z",
     "shell.execute_reply": "2023-08-21T22:45:42.704051Z",
     "shell.execute_reply.started": "2023-08-21T22:45:29.567171Z"
    },
    "executionInfo": {
     "elapsed": 7682,
     "status": "ok",
     "timestamp": 1692630033814,
     "user": {
      "displayName": "Kelly Butler",
      "userId": "08515498257456133265"
     },
     "user_tz": 240
    },
    "id": "OQSx6DFa_6_l",
    "outputId": "805f934a-7668-46ab-be66-b662c63531b7"
   },
   "outputs": [],
   "source": [
    "#!pip install python-resize-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961d3922",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "444ae7f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-21T21:57:47.622595Z",
     "iopub.status.busy": "2023-08-21T21:57:47.622205Z",
     "iopub.status.idle": "2023-08-21T21:57:59.169832Z",
     "shell.execute_reply": "2023-08-21T21:57:59.168401Z",
     "shell.execute_reply.started": "2023-08-21T21:57:47.622554Z"
    }
   },
   "outputs": [],
   "source": [
    "#! pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0cef3940",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-21T22:45:42.708093Z",
     "iopub.status.busy": "2023-08-21T22:45:42.707736Z",
     "iopub.status.idle": "2023-08-21T22:45:42.728712Z",
     "shell.execute_reply": "2023-08-21T22:45:42.727808Z",
     "shell.execute_reply.started": "2023-08-21T22:45:42.708059Z"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1692630036271,
     "user": {
      "displayName": "Kelly Butler",
      "userId": "08515498257456133265"
     },
     "user_tz": 240
    },
    "id": "d4ef7ab0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, UpSampling2D, Activation, Flatten, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from skimage import color\n",
    "from PIL import Image\n",
    "import imageio\n",
    "from resizeimage import resizeimage\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2940e136",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/butler/Documents/springboard_bootcamp/Classification_of_Indian_clothing_images/data/interim/test_one_hot.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "602ac0a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>image_path</th>\n",
       "      <th>dhoti_pants</th>\n",
       "      <th>saree</th>\n",
       "      <th>sherwanis</th>\n",
       "      <th>palazzos</th>\n",
       "      <th>nehru_jackets</th>\n",
       "      <th>petticoats</th>\n",
       "      <th>blouse</th>\n",
       "      <th>dupattas</th>\n",
       "      <th>gowns</th>\n",
       "      <th>lehenga</th>\n",
       "      <th>women_kurta</th>\n",
       "      <th>kurta_men</th>\n",
       "      <th>mojaris_men</th>\n",
       "      <th>mojaris_women</th>\n",
       "      <th>leggings_and_salwars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>images/test/0.jpeg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>images/test/1.jpeg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>images/test/2.jpeg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>images/test/3.jpeg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>images/test/4.jpeg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0          image_path  dhoti_pants  saree  sherwanis  palazzos  \\\n",
       "0           0  images/test/0.jpeg            0      1          0         0   \n",
       "1           1  images/test/1.jpeg            0      1          0         0   \n",
       "2           2  images/test/2.jpeg            0      1          0         0   \n",
       "3           3  images/test/3.jpeg            0      1          0         0   \n",
       "4           4  images/test/4.jpeg            0      1          0         0   \n",
       "\n",
       "   nehru_jackets  petticoats  blouse  dupattas  gowns  lehenga  women_kurta  \\\n",
       "0              0           0       0         0      0        0            0   \n",
       "1              0           0       0         0      0        0            0   \n",
       "2              0           0       0         0      0        0            0   \n",
       "3              0           0       0         0      0        0            0   \n",
       "4              0           0       0         0      0        0            0   \n",
       "\n",
       "   kurta_men  mojaris_men  mojaris_women  leggings_and_salwars  \n",
       "0          0            0              0                     0  \n",
       "1          0            0              0                     0  \n",
       "2          0            0              0                     0  \n",
       "3          0            0              0                     0  \n",
       "4          0            0              0                     0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3cec6bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b0cd85f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          images/test/0.jpeg\n",
       "1          images/test/1.jpeg\n",
       "2          images/test/2.jpeg\n",
       "3          images/test/3.jpeg\n",
       "4          images/test/4.jpeg\n",
       "                ...          \n",
       "6741    images/test/7495.jpeg\n",
       "6742    images/test/7496.jpeg\n",
       "6743    images/test/7497.jpeg\n",
       "6744    images/test/7498.jpeg\n",
       "6745    images/test/7499.jpeg\n",
       "Name: image_path, Length: 6746, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = df.image_path\n",
    "image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2f60a467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6746"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d5194410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'images/test/0.jpeg'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5912f647",
   "metadata": {},
   "source": [
    "Resizing test images and making them grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "54044d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "direct = '/Users/butler/Documents/springboard_bootcamp/Classification_of_Indian_clothing_images/data/raw/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7ad357d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "direct1 = '/Users/butler/Documents/springboard_bootcamp/Classification_of_Indian_clothing_images/data/interim/resized_70_gray/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "57c4f3ea",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "execution": {
     "iopub.execute_input": "2023-08-21T19:50:35.064764Z",
     "iopub.status.busy": "2023-08-21T19:50:35.064324Z",
     "iopub.status.idle": "2023-08-21T19:50:35.484096Z",
     "shell.execute_reply": "2023-08-21T19:50:35.482926Z",
     "shell.execute_reply.started": "2023-08-21T19:50:35.064727Z"
    },
    "executionInfo": {
     "elapsed": 57,
     "status": "ok",
     "timestamp": 1692630284714,
     "user": {
      "displayName": "Kelly Butler",
      "userId": "08515498257456133265"
     },
     "user_tz": 240
    },
    "id": "_nku4OXgiwoQ",
    "outputId": "8e83a7a5-4ed2-4adf-fa41-6deafbd0efba"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'IMAGES/TEST/0.JPEG'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/butler/Documents/springboard_bootcamp/Classification_of_Indian_clothing_images/notebooks/resizing_70_70_grayscale.ipynb Cell 14\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/butler/Documents/springboard_bootcamp/Classification_of_Indian_clothing_images/notebooks/resizing_70_70_grayscale.ipynb#X16sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m img \u001b[39m=\u001b[39m resizeimage\u001b[39m.\u001b[39mresize_contain(img, [\u001b[39m70\u001b[39m, \u001b[39m70\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/butler/Documents/springboard_bootcamp/Classification_of_Indian_clothing_images/notebooks/resizing_70_70_grayscale.ipynb#X16sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mconvert(\u001b[39m'\u001b[39m\u001b[39mL\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/butler/Documents/springboard_bootcamp/Classification_of_Indian_clothing_images/notebooks/resizing_70_70_grayscale.ipynb#X16sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m img\u001b[39m.\u001b[39;49msave(direct, image_path[i])\n",
      "File \u001b[0;32m~/anaconda3/envs/cnn/lib/python3.9/site-packages/PIL/Image.py:2400\u001b[0m, in \u001b[0;36mImage.save\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2398\u001b[0m     save_handler \u001b[39m=\u001b[39m SAVE_ALL[\u001b[39mformat\u001b[39m\u001b[39m.\u001b[39mupper()]\n\u001b[1;32m   2399\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2400\u001b[0m     save_handler \u001b[39m=\u001b[39m SAVE[\u001b[39mformat\u001b[39;49m\u001b[39m.\u001b[39;49mupper()]\n\u001b[1;32m   2402\u001b[0m created \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   2403\u001b[0m \u001b[39mif\u001b[39;00m open_fp:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'IMAGES/TEST/0.JPEG'"
     ]
    }
   ],
   "source": [
    "for i in range(len(image_path)):\n",
    "    path = os.path.join(direct, image_path[i])\n",
    "\n",
    "    img = Image.open(path)\n",
    "        \n",
    "    img = resizeimage.resize_contain(img, [70, 70])\n",
    "    img = img.convert('L')\n",
    "    \n",
    "    img.save(direct, image_path[i])\n",
    "#plt.imshow(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5eab0002",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "execution": {
     "iopub.execute_input": "2023-08-21T19:50:59.449101Z",
     "iopub.status.busy": "2023-08-21T19:50:59.448627Z",
     "iopub.status.idle": "2023-08-21T19:50:59.818219Z",
     "shell.execute_reply": "2023-08-21T19:50:59.815939Z",
     "shell.execute_reply.started": "2023-08-21T19:50:59.449062Z"
    },
    "executionInfo": {
     "elapsed": 57,
     "status": "ok",
     "timestamp": 1692630284714,
     "user": {
      "displayName": "Kelly Butler",
      "userId": "08515498257456133265"
     },
     "user_tz": 240
    },
    "id": "_nku4OXgiwoQ",
    "outputId": "8e83a7a5-4ed2-4adf-fa41-6deafbd0efba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7afa2634d1b0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = Image.open('/kaggle/input/indo-fashion-dataset/images/train/60000.jpeg')\n",
    "    # resize image (contain)\n",
    "img = resizeimage.resize_contain(img, [32, 32])\n",
    "    # covert to RBA incase it's RGBA\n",
    "img = img.convert(\"RGB\")\n",
    "#img.save('/content/images/train_60000_resized-image.jpg', img.format)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6495576b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 49,
     "status": "ok",
     "timestamp": 1692630284714,
     "user": {
      "displayName": "Kelly Butler",
      "userId": "08515498257456133265"
     },
     "user_tz": 240
    },
    "id": "1xqma-7o1Lfs",
    "outputId": "a1f1e044-cf1e-485a-ac53-215f5cb8804a"
   },
   "outputs": [],
   "source": [
    "img = imageio.imread('/kaggle/input/indo-fashion-dataset/images/train/0.jpeg')\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0259764c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "executionInfo": {
     "elapsed": 57,
     "status": "ok",
     "timestamp": 1692630284714,
     "user": {
      "displayName": "Kelly Butler",
      "userId": "08515498257456133265"
     },
     "user_tz": 240
    },
    "id": "_nku4OXgiwoQ",
    "outputId": "8e83a7a5-4ed2-4adf-fa41-6deafbd0efba"
   },
   "outputs": [],
   "source": [
    "img = Image.open('/kaggle/input/indo-fashion-dataset/images/train/60000.jpeg')\n",
    "    # resize image (contain)\n",
    "img = resizeimage.resize_contain(img, [256, 256])\n",
    "    # covert to RBA incase it's RGBA\n",
    "img = img.convert(\"RGB\")\n",
    "#img.save('/content/images/train_60000_resized-image.jpg', img.format)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e9d8ee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 49,
     "status": "ok",
     "timestamp": 1692630284714,
     "user": {
      "displayName": "Kelly Butler",
      "userId": "08515498257456133265"
     },
     "user_tz": 240
    },
    "id": "1xqma-7o1Lfs",
    "outputId": "a1f1e044-cf1e-485a-ac53-215f5cb8804a"
   },
   "outputs": [],
   "source": [
    "img = imageio.imread('/kaggle/input/indo-fashion-dataset/images/train/0.jpeg')\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62f7178",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "executionInfo": {
     "elapsed": 1396,
     "status": "ok",
     "timestamp": 1692630286066,
     "user": {
      "displayName": "Kelly Butler",
      "userId": "08515498257456133265"
     },
     "user_tz": 240
    },
    "id": "ctmOtql6AYN2",
    "outputId": "110c75ea-9d3b-4ae7-9cf5-73e051ce3406"
   },
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff318b8",
   "metadata": {
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1692630286067,
     "user": {
      "displayName": "Kelly Butler",
      "userId": "08515498257456133265"
     },
     "user_tz": 240
    },
    "id": "NEGPmxFQmItH"
   },
   "outputs": [],
   "source": [
    "\n",
    "img = Image.open('/kaggle/input/indo-fashion-dataset/images/train/0.jpeg')\n",
    "    # resize image (contain)\n",
    "img = resizeimage.resize_contain(img, [256, 256])\n",
    "    # covert to RBA incase it's RGBA\n",
    "img = img.convert(\"RGB\")\n",
    "#img.save('/content/images/train_0_resized-image.jpg', img.format)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fed5ce8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1692630286067,
     "user": {
      "displayName": "Kelly Butler",
      "userId": "08515498257456133265"
     },
     "user_tz": 240
    },
    "id": "DVyZloWgocjm",
    "outputId": "b7206554-4903-4faa-892a-31c43c214eb5"
   },
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156cc297",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1692630286067,
     "user": {
      "displayName": "Kelly Butler",
      "userId": "08515498257456133265"
     },
     "user_tz": 240
    },
    "id": "gXr4X1sdBwcf",
    "outputId": "11e44652-16e2-465e-cea1-e657eb0aa4fc"
   },
   "outputs": [],
   "source": [
    "img = imageio.imread('/kaggle/input/indo-fashion-dataset/images/train/20000.jpeg')\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad37378",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1692630286067,
     "user": {
      "displayName": "Kelly Butler",
      "userId": "08515498257456133265"
     },
     "user_tz": 240
    },
    "id": "VaiQLp4qB-fV",
    "outputId": "c2cab67d-3053-4d70-98fe-af0dd36582e5"
   },
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ac3abe",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1692630286068,
     "user": {
      "displayName": "Kelly Butler",
      "userId": "08515498257456133265"
     },
     "user_tz": 240
    },
    "id": "oTbjSlwrBmoa"
   },
   "outputs": [],
   "source": [
    "img = Image.open('/kaggle/input/indo-fashion-dataset/images/train/20000.jpeg')\n",
    "    # resize image (contain)\n",
    "img = resizeimage.resize_contain(img, [256, 256])\n",
    "    # covert to RBA incase it's RGBA\n",
    "img = img.convert(\"RGB\")\n",
    "#img.save('/content/images/train_20000_resized-image.jpg', img.format)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058ef10a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "executionInfo": {
     "elapsed": 592,
     "status": "ok",
     "timestamp": 1692630286649,
     "user": {
      "displayName": "Kelly Butler",
      "userId": "08515498257456133265"
     },
     "user_tz": 240
    },
    "id": "vHn3lHVLBsoU",
    "outputId": "a6d2e885-9321-4d51-d93c-ba430d06d1fc"
   },
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4ed0040",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-21T22:46:54.732890Z",
     "iopub.status.busy": "2023-08-21T22:46:54.732514Z",
     "iopub.status.idle": "2023-08-21T22:46:54.775583Z",
     "shell.execute_reply": "2023-08-21T22:46:54.774550Z",
     "shell.execute_reply.started": "2023-08-21T22:46:54.732858Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.get_dummies(data=df_train, columns=['class_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "44ca88b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-21T22:46:55.652444Z",
     "iopub.status.busy": "2023-08-21T22:46:55.651751Z",
     "iopub.status.idle": "2023-08-21T22:46:55.670377Z",
     "shell.execute_reply": "2023-08-21T22:46:55.669385Z",
     "shell.execute_reply.started": "2023-08-21T22:46:55.652410Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>class_label_blouse</th>\n",
       "      <th>class_label_dhoti_pants</th>\n",
       "      <th>class_label_dupattas</th>\n",
       "      <th>class_label_gowns</th>\n",
       "      <th>class_label_kurta_men</th>\n",
       "      <th>class_label_leggings_and_salwars</th>\n",
       "      <th>class_label_lehenga</th>\n",
       "      <th>class_label_mojaris_men</th>\n",
       "      <th>class_label_mojaris_women</th>\n",
       "      <th>class_label_nehru_jackets</th>\n",
       "      <th>class_label_palazzos</th>\n",
       "      <th>class_label_petticoats</th>\n",
       "      <th>class_label_saree</th>\n",
       "      <th>class_label_sherwanis</th>\n",
       "      <th>class_label_women_kurta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>images/train/0.jpeg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>images/train/1.jpeg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>images/train/2.jpeg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>images/train/3.jpeg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>images/train/4.jpeg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            image_path  class_label_blouse  class_label_dhoti_pants  \\\n",
       "0  images/train/0.jpeg                   0                        0   \n",
       "1  images/train/1.jpeg                   0                        0   \n",
       "2  images/train/2.jpeg                   0                        0   \n",
       "3  images/train/3.jpeg                   0                        0   \n",
       "4  images/train/4.jpeg                   0                        0   \n",
       "\n",
       "   class_label_dupattas  class_label_gowns  class_label_kurta_men  \\\n",
       "0                     0                  0                      0   \n",
       "1                     0                  0                      0   \n",
       "2                     0                  0                      0   \n",
       "3                     0                  0                      0   \n",
       "4                     0                  0                      0   \n",
       "\n",
       "   class_label_leggings_and_salwars  class_label_lehenga  \\\n",
       "0                                 0                    0   \n",
       "1                                 0                    0   \n",
       "2                                 0                    0   \n",
       "3                                 0                    0   \n",
       "4                                 0                    0   \n",
       "\n",
       "   class_label_mojaris_men  class_label_mojaris_women  \\\n",
       "0                        0                          0   \n",
       "1                        0                          0   \n",
       "2                        0                          0   \n",
       "3                        0                          0   \n",
       "4                        0                          0   \n",
       "\n",
       "   class_label_nehru_jackets  class_label_palazzos  class_label_petticoats  \\\n",
       "0                          0                     0                       0   \n",
       "1                          0                     0                       0   \n",
       "2                          0                     0                       0   \n",
       "3                          0                     0                       0   \n",
       "4                          0                     0                       0   \n",
       "\n",
       "   class_label_saree  class_label_sherwanis  class_label_women_kurta  \n",
       "0                  1                      0                        0  \n",
       "1                  1                      0                        0  \n",
       "2                  1                      0                        0  \n",
       "3                  1                      0                        0  \n",
       "4                  1                      0                        0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "997881f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-21T22:46:56.894645Z",
     "iopub.status.busy": "2023-08-21T22:46:56.894285Z",
     "iopub.status.idle": "2023-08-21T22:46:56.906076Z",
     "shell.execute_reply": "2023-08-21T22:46:56.904834Z",
     "shell.execute_reply.started": "2023-08-21T22:46:56.894615Z"
    }
   },
   "outputs": [],
   "source": [
    "df_val = pd.get_dummies(data=df_val, columns=['class_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8cc30449",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-21T22:46:58.739382Z",
     "iopub.status.busy": "2023-08-21T22:46:58.739018Z",
     "iopub.status.idle": "2023-08-21T22:46:58.757081Z",
     "shell.execute_reply": "2023-08-21T22:46:58.755744Z",
     "shell.execute_reply.started": "2023-08-21T22:46:58.739354Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>class_label_blouse</th>\n",
       "      <th>class_label_dhoti_pants</th>\n",
       "      <th>class_label_dupattas</th>\n",
       "      <th>class_label_gowns</th>\n",
       "      <th>class_label_kurta_men</th>\n",
       "      <th>class_label_leggings_and_salwars</th>\n",
       "      <th>class_label_lehenga</th>\n",
       "      <th>class_label_mojaris_men</th>\n",
       "      <th>class_label_mojaris_women</th>\n",
       "      <th>class_label_nehru_jackets</th>\n",
       "      <th>class_label_palazzos</th>\n",
       "      <th>class_label_petticoats</th>\n",
       "      <th>class_label_saree</th>\n",
       "      <th>class_label_sherwanis</th>\n",
       "      <th>class_label_women_kurta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>images/val/0.jpeg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>images/val/1.jpeg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>images/val/2.jpeg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>images/val/3.jpeg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>images/val/4.jpeg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          image_path  class_label_blouse  class_label_dhoti_pants  \\\n",
       "0  images/val/0.jpeg                   0                        0   \n",
       "1  images/val/1.jpeg                   0                        0   \n",
       "2  images/val/2.jpeg                   0                        0   \n",
       "3  images/val/3.jpeg                   0                        0   \n",
       "4  images/val/4.jpeg                   0                        0   \n",
       "\n",
       "   class_label_dupattas  class_label_gowns  class_label_kurta_men  \\\n",
       "0                     0                  0                      0   \n",
       "1                     0                  0                      0   \n",
       "2                     0                  0                      0   \n",
       "3                     0                  0                      0   \n",
       "4                     0                  0                      0   \n",
       "\n",
       "   class_label_leggings_and_salwars  class_label_lehenga  \\\n",
       "0                                 0                    0   \n",
       "1                                 0                    0   \n",
       "2                                 0                    0   \n",
       "3                                 0                    0   \n",
       "4                                 0                    0   \n",
       "\n",
       "   class_label_mojaris_men  class_label_mojaris_women  \\\n",
       "0                        0                          0   \n",
       "1                        0                          0   \n",
       "2                        0                          0   \n",
       "3                        0                          0   \n",
       "4                        0                          0   \n",
       "\n",
       "   class_label_nehru_jackets  class_label_palazzos  class_label_petticoats  \\\n",
       "0                          0                     0                       0   \n",
       "1                          0                     0                       0   \n",
       "2                          0                     0                       0   \n",
       "3                          0                     0                       0   \n",
       "4                          0                     0                       0   \n",
       "\n",
       "   class_label_saree  class_label_sherwanis  class_label_women_kurta  \n",
       "0                  1                      0                        0  \n",
       "1                  1                      0                        0  \n",
       "2                  1                      0                        0  \n",
       "3                  1                      0                        0  \n",
       "4                  1                      0                        0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3a8b3d4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-21T22:46:59.546778Z",
     "iopub.status.busy": "2023-08-21T22:46:59.546349Z",
     "iopub.status.idle": "2023-08-21T22:46:59.558593Z",
     "shell.execute_reply": "2023-08-21T22:46:59.557435Z",
     "shell.execute_reply.started": "2023-08-21T22:46:59.546741Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test = pd.get_dummies(data=df_test, columns=['class_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "32f4e07f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-21T22:47:00.492891Z",
     "iopub.status.busy": "2023-08-21T22:47:00.492505Z",
     "iopub.status.idle": "2023-08-21T22:47:00.500260Z",
     "shell.execute_reply": "2023-08-21T22:47:00.499349Z",
     "shell.execute_reply.started": "2023-08-21T22:47:00.492864Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['image_path', 'class_label_blouse', 'class_label_dhoti_pants',\n",
       "       'class_label_dupattas', 'class_label_gowns', 'class_label_kurta_men',\n",
       "       'class_label_leggings_and_salwars', 'class_label_lehenga',\n",
       "       'class_label_mojaris_men', 'class_label_mojaris_women',\n",
       "       'class_label_nehru_jackets', 'class_label_palazzos',\n",
       "       'class_label_petticoats', 'class_label_saree', 'class_label_sherwanis',\n",
       "       'class_label_women_kurta'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d25c186",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "executionInfo": {
     "elapsed": 119910,
     "status": "error",
     "timestamp": 1692630406556,
     "user": {
      "displayName": "Kelly Butler",
      "userId": "08515498257456133265"
     },
     "user_tz": 240
    },
    "id": "29xr_n1TD1MA",
    "outputId": "9603cd45-8ae6-43e5-e3b0-5cfd78fd7ffc"
   },
   "outputs": [],
   "source": [
    "#resized_imgs = []\n",
    "#for i in range(len(df_train)):\n",
    "  #img = Image.open(f'/content/images/train/{i}.jpeg')\n",
    "  #img = resizeimage.resize_contain(img, [256, 256])\n",
    "  #img = img.convert(\"RGB\")\n",
    "  #resized_imgs.append(img)\n",
    "# requires too much ram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cb59d7",
   "metadata": {
    "executionInfo": {
     "elapsed": 167,
     "status": "ok",
     "timestamp": 1692626793820,
     "user": {
      "displayName": "Kelly Butler",
      "userId": "08515498257456133265"
     },
     "user_tz": 240
    },
    "id": "G18rMR--nyPk"
   },
   "outputs": [],
   "source": [
    "#train_datagen=ImageDataGenerator(rescale=1./255)\n",
    "#train_generator=datagen.flow_from_dataframe(dataframe=df_train, directory='/content', x_col='image_path', y_col='class_label', class_mode='categorical', target_size=(32,32), batch_size=32, seed=26, save_to_dir='/content/drive/My Drive/capstone_3/preprocessed_data', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8a1a09e6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-21T22:47:06.676068Z",
     "iopub.status.busy": "2023-08-21T22:47:06.675647Z",
     "iopub.status.idle": "2023-08-21T22:47:11.684491Z",
     "shell.execute_reply": "2023-08-21T22:47:11.680928Z",
     "shell.execute_reply.started": "2023-08-21T22:47:06.676037Z"
    },
    "executionInfo": {
     "elapsed": 989,
     "status": "ok",
     "timestamp": 1692627052803,
     "user": {
      "displayName": "Kelly Butler",
      "userId": "08515498257456133265"
     },
     "user_tz": 240
    },
    "id": "FJPDKio3Xxzb",
    "outputId": "dfd49772-9604-4fd3-ce99-b57fc526aeae"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 10\u001b[0m\n\u001b[1;32m      2\u001b[0m columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_label_blouse\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_label_dhoti_pants\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_label_dupattas\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_label_gowns\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_label_kurta_men\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_label_leggings_and_salwars\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_label_lehenga\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_label_petticoats\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_label_saree\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_label_sherwanis\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      8\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_label_women_kurta\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      9\u001b[0m train_datagen\u001b[38;5;241m=\u001b[39mImageDataGenerator(rescale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m train_generator \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_datagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow_from_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/kaggle/input/indo-fashion-dataset\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage_path\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m26\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_to_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/kaggle/working\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mraw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/preprocessing/image.py:1806\u001b[0m, in \u001b[0;36mImageDataGenerator.flow_from_dataframe\u001b[0;34m(self, dataframe, directory, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, subset, interpolation, validate_filenames, **kwargs)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop_duplicates\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m   1800\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1801\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop_duplicates is deprecated, you can drop duplicates \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1802\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mby using the pandas.DataFrame.drop_duplicates method.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1803\u001b[0m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[1;32m   1804\u001b[0m     )\n\u001b[0;32m-> 1806\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1807\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1808\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1809\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1810\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1811\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1812\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1813\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1814\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1815\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1816\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1817\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1818\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1819\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1820\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1821\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_to_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_to_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1822\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1823\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1824\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1825\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1826\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate_filenames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_filenames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1827\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1828\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/preprocessing/image.py:972\u001b[0m, in \u001b[0;36mDataFrameIterator.__init__\u001b[0;34m(self, dataframe, directory, image_data_generator, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, subset, interpolation, keep_aspect_ratio, dtype, validate_filenames)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params(df, x_col, y_col, weight_col, classes)\n\u001b[1;32m    969\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    970\u001b[0m     validate_filenames\n\u001b[1;32m    971\u001b[0m ):  \u001b[38;5;66;03m# check which image files are valid and keep them\u001b[39;00m\n\u001b[0;32m--> 972\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_filter_valid_filepaths\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_col\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m class_mode \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulti_output\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m]:\n\u001b[1;32m    974\u001b[0m     df, classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filter_classes(df, y_col, classes)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/preprocessing/image.py:1132\u001b[0m, in \u001b[0;36mDataFrameIterator._filter_valid_filepaths\u001b[0;34m(self, df, x_col)\u001b[0m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Keep only dataframe rows with valid filenames.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m \n\u001b[1;32m   1122\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;124;03m    absolute paths to image files\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m filepaths \u001b[38;5;241m=\u001b[39m df[x_col]\u001b[38;5;241m.\u001b[39mmap(\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m fname: os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdirectory, fname)\n\u001b[1;32m   1131\u001b[0m )\n\u001b[0;32m-> 1132\u001b[0m mask \u001b[38;5;241m=\u001b[39m \u001b[43mfilepaths\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhite_list_formats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1134\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1135\u001b[0m n_invalid \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m~\u001b[39mmask)\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_invalid:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4661\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4662\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4666\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4667\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4668\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4669\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4670\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4770\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/apply.py:1174\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1172\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1173\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m-> 1174\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1178\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1181\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1182\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/_libs/lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/apply.py:142\u001b[0m, in \u001b[0;36mApply.__init__.<locals>.f\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m(x):\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/preprocessing/image.py:838\u001b[0m, in \u001b[0;36mvalidate_filename\u001b[0;34m(filename, white_list_formats)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_filename\u001b[39m(filename, white_list_formats):\n\u001b[1;32m    830\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check if a filename refers to a valid file.\u001b[39;00m\n\u001b[1;32m    831\u001b[0m \n\u001b[1;32m    832\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[38;5;124;03m        A boolean value indicating if the filename is valid or not\u001b[39;00m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 838\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith(white_list_formats) \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misfile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/genericpath.py:30\u001b[0m, in \u001b[0;36misfile\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Test whether a path is a regular file\"\"\"\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 30\u001b[0m     st \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Creating generator images sizes 256 x 256\n",
    "columns = ['class_label_blouse', 'class_label_dhoti_pants',\n",
    "       'class_label_dupattas', 'class_label_gowns', 'class_label_kurta_men',\n",
    "       'class_label_leggings_and_salwars', 'class_label_lehenga',\n",
    "       'class_label_mojaris_men', 'class_label_mojaris_women',\n",
    "       'class_label_nehru_jackets', 'class_label_palazzos',\n",
    "       'class_label_petticoats', 'class_label_saree', 'class_label_sherwanis',\n",
    "       'class_label_women_kurta']\n",
    "train_datagen=ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_dataframe(dataframe=df_train, directory='/kaggle/input/indo-fashion-dataset', x_col='image_path', y_col=columns, target_size=(256,256), batch_size=32, seed=26, save_to_dir='/kaggle/working', class_mode='raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4787c7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 418,
     "status": "ok",
     "timestamp": 1692627166048,
     "user": {
      "displayName": "Kelly Butler",
      "userId": "08515498257456133265"
     },
     "user_tz": 240
    },
    "id": "iMCAsrzPb67i",
    "outputId": "863fbf8f-08c1-4360-d2cb-2fd044f1ac9f"
   },
   "outputs": [],
   "source": [
    "val_datagen=ImageDataGenerator(rescale=1./255)\n",
    "val_generator = val_datagen.flow_from_dataframe(dataframe=df_val, directory='/kaggle/input/indo-fashion-dataset', x_col='image_path', y_col=columns, target_size=(256,256), batch_size=32, seed=26, save_to_dir='/kaggle/working', class_mode='raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2e8a66",
   "metadata": {
    "executionInfo": {
     "elapsed": 407,
     "status": "ok",
     "timestamp": 1692625052410,
     "user": {
      "displayName": "Kelly Butler",
      "userId": "08515498257456133265"
     },
     "user_tz": 240
    },
    "id": "50c079b7"
   },
   "outputs": [],
   "source": [
    "# most of code is from https://saturncloud.io/blog/how-to-handle-different-image-sizes-in-tensorflow-cnn-training/#:~:text=Solution%202%3A%20Use%20Variable%20Input,keras.\n",
    "# Thursday, July 06, 2023\n",
    "\n",
    "#def resize_image(image, size=(256, 256)):\n",
    "    #return tf.image.resize(image, size)\n",
    "\n",
    "#train_dataset = tf.data.Dataset.list_files('/content/images/train/*.jpg')\n",
    "#train_dataset = train_dataset.map(lambda x: tf.io.read_file(x))\n",
    "\n",
    "#train_dataset = train_dataset.map(lambda x: tf.image.decode_jpeg(x, channels=3))\n",
    "\n",
    "# Apply resizing to dataset\n",
    "#train_dataset = train_dataset.map(lambda x: resize_image(x, size=(256, 256)))\n",
    "\n",
    "#val_dataset = tf.data.Dataset.list_files('/content/images/val/*.jpg')\n",
    "#val_dataset = val_dataset.map(lambda x: tf.io.read_file(x))\n",
    "\n",
    "#val_dataset = val_dataset.map(lambda x: tf.image.decode_jpeg(x, channels=3))\n",
    "\n",
    "#val_dataset = val_dataset.map(lambda x: resize_image(x, size=(256, 256)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b32d3f",
   "metadata": {
    "executionInfo": {
     "elapsed": 573,
     "status": "ok",
     "timestamp": 1692629951064,
     "user": {
      "displayName": "Kelly Butler",
      "userId": "08515498257456133265"
     },
     "user_tz": 240
    },
    "id": "PsGLmgnLUSNX"
   },
   "outputs": [],
   "source": [
    "# Setting up model\n",
    "img_width, img_height = 256, 256\n",
    "\n",
    "train_data = train_generator\n",
    "val_data = val_generator\n",
    "nb_train_samples = 91166\n",
    "nb_validation_samples = 7500\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "\n",
    "input_shape = (img_width, img_height, 3)\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(15))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f66c415",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 35249,
     "status": "error",
     "timestamp": 1692629988242,
     "user": {
      "displayName": "Kelly Butler",
      "userId": "08515498257456133265"
     },
     "user_tz": 240
    },
    "id": "BaB7j4UvPlQ0",
    "outputId": "9a420f8b-0a34-4361-b44d-6df1e34fb08a"
   },
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    x=train_generator,\n",
    "    y=None,\n",
    "    validation_data=val_generator,\n",
    "    epochs=5,\n",
    "    verbose=\"auto\",\n",
    "    callbacks=None,\n",
    "    validation_split=0.0,\n",
    "    shuffle=True,\n",
    "    class_weight=None,\n",
    "    sample_weight=None,\n",
    "    initial_epoch=0,\n",
    "    steps_per_epoch=None,\n",
    "    validation_steps=3,\n",
    "    validation_batch_size=batch_size,\n",
    "    validation_freq=4,\n",
    "    max_queue_size=10,\n",
    "    use_multiprocessing=True,\n",
    "    workers=6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc007cf",
   "metadata": {
    "id": "s2lJLvacPlOR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d764a89",
   "metadata": {},
   "source": [
    "Now trying smaller images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ec4ec35",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-21T19:51:35.516674Z",
     "iopub.status.busy": "2023-08-21T19:51:35.515752Z",
     "iopub.status.idle": "2023-08-21T19:52:28.731161Z",
     "shell.execute_reply": "2023-08-21T19:52:28.729896Z",
     "shell.execute_reply.started": "2023-08-21T19:51:35.516632Z"
    },
    "executionInfo": {
     "elapsed": 989,
     "status": "ok",
     "timestamp": 1692627052803,
     "user": {
      "displayName": "Kelly Butler",
      "userId": "08515498257456133265"
     },
     "user_tz": 240
    },
    "id": "FJPDKio3Xxzb",
    "outputId": "dfd49772-9604-4fd3-ce99-b57fc526aeae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 91166 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# Creating generator for 32 x 32 sized images\n",
    "columns = ['class_label_blouse', 'class_label_dhoti_pants',\n",
    "       'class_label_dupattas', 'class_label_gowns', 'class_label_kurta_men',\n",
    "       'class_label_leggings_and_salwars', 'class_label_lehenga',\n",
    "       'class_label_mojaris_men', 'class_label_mojaris_women',\n",
    "       'class_label_nehru_jackets', 'class_label_palazzos',\n",
    "       'class_label_petticoats', 'class_label_saree', 'class_label_sherwanis',\n",
    "       'class_label_women_kurta']\n",
    "train_datagen=ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_dataframe(dataframe=df_train, directory='/kaggle/input/indo-fashion-dataset', x_col='image_path', y_col=columns, target_size=(32,32), batch_size=32, seed=26, save_to_dir='/kaggle/working', class_mode='raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d505878",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-21T19:52:28.735573Z",
     "iopub.status.busy": "2023-08-21T19:52:28.735095Z",
     "iopub.status.idle": "2023-08-21T19:52:32.253663Z",
     "shell.execute_reply": "2023-08-21T19:52:32.252374Z",
     "shell.execute_reply.started": "2023-08-21T19:52:28.735524Z"
    },
    "executionInfo": {
     "elapsed": 418,
     "status": "ok",
     "timestamp": 1692627166048,
     "user": {
      "displayName": "Kelly Butler",
      "userId": "08515498257456133265"
     },
     "user_tz": 240
    },
    "id": "iMCAsrzPb67i",
    "outputId": "863fbf8f-08c1-4360-d2cb-2fd044f1ac9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7500 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "val_datagen=ImageDataGenerator(rescale=1./255)\n",
    "val_generator = val_datagen.flow_from_dataframe(dataframe=df_val, directory='/kaggle/input/indo-fashion-dataset', x_col='image_path', y_col=columns, target_size=(32,32), batch_size=32, seed=26, save_to_dir='/kaggle/working', class_mode='raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "49327993",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-21T19:53:24.184863Z",
     "iopub.status.busy": "2023-08-21T19:53:24.184367Z",
     "iopub.status.idle": "2023-08-21T19:53:27.640450Z",
     "shell.execute_reply": "2023-08-21T19:53:27.639230Z",
     "shell.execute_reply.started": "2023-08-21T19:53:24.184800Z"
    },
    "executionInfo": {
     "elapsed": 573,
     "status": "ok",
     "timestamp": 1692629951064,
     "user": {
      "displayName": "Kelly Butler",
      "userId": "08515498257456133265"
     },
     "user_tz": 240
    },
    "id": "PsGLmgnLUSNX"
   },
   "outputs": [],
   "source": [
    "# Setting up model\n",
    "img_width, img_height = 32, 32\n",
    "\n",
    "train_data = train_generator\n",
    "val_data = val_generator\n",
    "nb_train_samples = 91166\n",
    "nb_validation_samples = 7500\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "\n",
    "input_shape = (img_width, img_height, 3)\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(15))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "29d876cc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2023-08-21T19:53:46.615508Z",
     "iopub.status.busy": "2023-08-21T19:53:46.615075Z",
     "iopub.status.idle": "2023-08-21T20:09:47.408085Z",
     "shell.execute_reply": "2023-08-21T20:09:47.405885Z",
     "shell.execute_reply.started": "2023-08-21T19:53:46.615472Z"
    },
    "executionInfo": {
     "elapsed": 35249,
     "status": "error",
     "timestamp": 1692629988242,
     "user": {
      "displayName": "Kelly Butler",
      "userId": "08515498257456133265"
     },
     "user_tz": 240
    },
    "id": "BaB7j4UvPlQ0",
    "outputId": "9a420f8b-0a34-4361-b44d-6df1e34fb08a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2849/2849 [==============================] - 217s 74ms/step - loss: 1.3831 - accuracy: 0.5580\n",
      "Epoch 2/50\n",
      "2849/2849 [==============================] - 198s 69ms/step - loss: 1.0064 - accuracy: 0.6766\n",
      "Epoch 3/50\n",
      "2849/2849 [==============================] - 197s 69ms/step - loss: 0.9100 - accuracy: 0.7082\n",
      "Epoch 4/50\n",
      "2849/2849 [==============================] - 197s 69ms/step - loss: 0.8566 - accuracy: 0.7253 - val_loss: 0.7467 - val_accuracy: 0.7083\n",
      "Epoch 5/50\n",
      "1783/2849 [=================>............] - ETA: 1:19 - loss: 0.8175 - accuracy: 0.7386"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\n2 root error(s) found.\n  (0) UNKNOWN:  OSError: [Errno 28] No space left on device: '/kaggle/working/_30684_5908004.png'\nmultiprocessing.pool.RemoteTraceback: \n\"\"\"\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/opt/conda/lib/python3.10/site-packages/keras/utils/data_utils.py\", line 647, in get_index\n    return _SHARED_SEQUENCES[uid][i]\n  File \"/opt/conda/lib/python3.10/site-packages/keras/preprocessing/image.py\", line 116, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n  File \"/opt/conda/lib/python3.10/site-packages/keras/preprocessing/image.py\", line 399, in _get_batches_of_transformed_samples\n    img.save(os.path.join(self.save_to_dir, fname))\n  File \"/opt/conda/lib/python3.10/site-packages/PIL/Image.py\", line 2429, in save\n    fp = builtins.open(filename, \"w+b\")\nOSError: [Errno 28] No space left on device: '/kaggle/working/_30684_5908004.png'\n\"\"\"\n\n\nThe above exception was the direct cause of the following exception:\n\n\nTraceback (most recent call last):\n\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n    ret = func(*args)\n\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/engine/data_adapter.py\", line 902, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/utils/data_utils.py\", line 870, in get\n    raise e\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/utils/data_utils.py\", line 861, in get\n    inputs = self.queue.get(block=True, timeout=5).get()\n\n  File \"/opt/conda/lib/python3.10/multiprocessing/pool.py\", line 774, in get\n    raise self._value\n\n  File \"/opt/conda/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/utils/data_utils.py\", line 647, in get_index\n    return _SHARED_SEQUENCES[uid][i]\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/preprocessing/image.py\", line 116, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/preprocessing/image.py\", line 399, in _get_batches_of_transformed_samples\n    img.save(os.path.join(self.save_to_dir, fname))\n\n  File \"/opt/conda/lib/python3.10/site-packages/PIL/Image.py\", line 2429, in save\n    fp = builtins.open(filename, \"w+b\")\n\nOSError: [Errno 28] No space left on device: '/kaggle/working/_30684_5908004.png'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_2]]\n  (1) UNKNOWN:  OSError: [Errno 28] No space left on device: '/kaggle/working/_30684_5908004.png'\nmultiprocessing.pool.RemoteTraceback: \n\"\"\"\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/opt/conda/lib/python3.10/site-packages/keras/utils/data_utils.py\", line 647, in get_index\n    return _SHARED_SEQUENCES[uid][i]\n  File \"/opt/conda/lib/python3.10/site-packages/keras/preprocessing/image.py\", line 116, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n  File \"/opt/conda/lib/python3.10/site-packages/keras/preprocessing/image.py\", line 399, in _get_batches_of_transformed_samples\n    img.save(os.path.join(self.save_to_dir, fname))\n  File \"/opt/conda/lib/python3.10/site-packages/PIL/Image.py\", line 2429, in save\n    fp = builtins.open(filename, \"w+b\")\nOSError: [Errno 28] No space left on device: '/kaggle/working/_30684_5908004.png'\n\"\"\"\n\n\nThe above exception was the direct cause of the following exception:\n\n\nTraceback (most recent call last):\n\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n    ret = func(*args)\n\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/engine/data_adapter.py\", line 902, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/utils/data_utils.py\", line 870, in get\n    raise e\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/utils/data_utils.py\", line 861, in get\n    inputs = self.queue.get(block=True, timeout=5).get()\n\n  File \"/opt/conda/lib/python3.10/multiprocessing/pool.py\", line 774, in get\n    raise self._value\n\n  File \"/opt/conda/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/utils/data_utils.py\", line 647, in get_index\n    return _SHARED_SEQUENCES[uid][i]\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/preprocessing/image.py\", line 116, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/preprocessing/image.py\", line 399, in _get_batches_of_transformed_samples\n    img.save(os.path.join(self.save_to_dir, fname))\n\n  File \"/opt/conda/lib/python3.10/site-packages/PIL/Image.py\", line 2429, in save\n    fp = builtins.open(filename, \"w+b\")\n\nOSError: [Errno 28] No space left on device: '/kaggle/working/_30684_5908004.png'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_1414]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnknownError\u001b[0m: Graph execution error:\n\n2 root error(s) found.\n  (0) UNKNOWN:  OSError: [Errno 28] No space left on device: '/kaggle/working/_30684_5908004.png'\nmultiprocessing.pool.RemoteTraceback: \n\"\"\"\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/opt/conda/lib/python3.10/site-packages/keras/utils/data_utils.py\", line 647, in get_index\n    return _SHARED_SEQUENCES[uid][i]\n  File \"/opt/conda/lib/python3.10/site-packages/keras/preprocessing/image.py\", line 116, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n  File \"/opt/conda/lib/python3.10/site-packages/keras/preprocessing/image.py\", line 399, in _get_batches_of_transformed_samples\n    img.save(os.path.join(self.save_to_dir, fname))\n  File \"/opt/conda/lib/python3.10/site-packages/PIL/Image.py\", line 2429, in save\n    fp = builtins.open(filename, \"w+b\")\nOSError: [Errno 28] No space left on device: '/kaggle/working/_30684_5908004.png'\n\"\"\"\n\n\nThe above exception was the direct cause of the following exception:\n\n\nTraceback (most recent call last):\n\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n    ret = func(*args)\n\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/engine/data_adapter.py\", line 902, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/utils/data_utils.py\", line 870, in get\n    raise e\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/utils/data_utils.py\", line 861, in get\n    inputs = self.queue.get(block=True, timeout=5).get()\n\n  File \"/opt/conda/lib/python3.10/multiprocessing/pool.py\", line 774, in get\n    raise self._value\n\n  File \"/opt/conda/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/utils/data_utils.py\", line 647, in get_index\n    return _SHARED_SEQUENCES[uid][i]\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/preprocessing/image.py\", line 116, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/preprocessing/image.py\", line 399, in _get_batches_of_transformed_samples\n    img.save(os.path.join(self.save_to_dir, fname))\n\n  File \"/opt/conda/lib/python3.10/site-packages/PIL/Image.py\", line 2429, in save\n    fp = builtins.open(filename, \"w+b\")\n\nOSError: [Errno 28] No space left on device: '/kaggle/working/_30684_5908004.png'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_2]]\n  (1) UNKNOWN:  OSError: [Errno 28] No space left on device: '/kaggle/working/_30684_5908004.png'\nmultiprocessing.pool.RemoteTraceback: \n\"\"\"\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/opt/conda/lib/python3.10/site-packages/keras/utils/data_utils.py\", line 647, in get_index\n    return _SHARED_SEQUENCES[uid][i]\n  File \"/opt/conda/lib/python3.10/site-packages/keras/preprocessing/image.py\", line 116, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n  File \"/opt/conda/lib/python3.10/site-packages/keras/preprocessing/image.py\", line 399, in _get_batches_of_transformed_samples\n    img.save(os.path.join(self.save_to_dir, fname))\n  File \"/opt/conda/lib/python3.10/site-packages/PIL/Image.py\", line 2429, in save\n    fp = builtins.open(filename, \"w+b\")\nOSError: [Errno 28] No space left on device: '/kaggle/working/_30684_5908004.png'\n\"\"\"\n\n\nThe above exception was the direct cause of the following exception:\n\n\nTraceback (most recent call last):\n\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n    ret = func(*args)\n\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/engine/data_adapter.py\", line 902, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/utils/data_utils.py\", line 870, in get\n    raise e\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/utils/data_utils.py\", line 861, in get\n    inputs = self.queue.get(block=True, timeout=5).get()\n\n  File \"/opt/conda/lib/python3.10/multiprocessing/pool.py\", line 774, in get\n    raise self._value\n\n  File \"/opt/conda/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/utils/data_utils.py\", line 647, in get_index\n    return _SHARED_SEQUENCES[uid][i]\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/preprocessing/image.py\", line 116, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/preprocessing/image.py\", line 399, in _get_batches_of_transformed_samples\n    img.save(os.path.join(self.save_to_dir, fname))\n\n  File \"/opt/conda/lib/python3.10/site-packages/PIL/Image.py\", line 2429, in save\n    fp = builtins.open(filename, \"w+b\")\n\nOSError: [Errno 28] No space left on device: '/kaggle/working/_30684_5908004.png'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_1414]"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    x=train_generator,\n",
    "    y=None,\n",
    "    validation_data=val_generator,\n",
    "    epochs=50,\n",
    "    verbose=\"auto\",\n",
    "    callbacks=None,\n",
    "    validation_split=0.0,\n",
    "    shuffle=True,\n",
    "    class_weight=None,\n",
    "    sample_weight=None,\n",
    "    initial_epoch=0,\n",
    "    steps_per_epoch=None,\n",
    "    validation_steps=3,\n",
    "    validation_batch_size=batch_size,\n",
    "    validation_freq=4,\n",
    "    max_queue_size=10,\n",
    "    use_multiprocessing=True,\n",
    "    workers=6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fc87cc",
   "metadata": {
    "id": "U-LAv-f8PlLj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eff2885",
   "metadata": {
    "id": "lplIeWKAPlJQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "661231ee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-21T22:47:36.580626Z",
     "iopub.status.busy": "2023-08-21T22:47:36.580253Z",
     "iopub.status.idle": "2023-08-21T22:48:47.513414Z",
     "shell.execute_reply": "2023-08-21T22:48:47.512407Z",
     "shell.execute_reply.started": "2023-08-21T22:47:36.580595Z"
    },
    "executionInfo": {
     "elapsed": 989,
     "status": "ok",
     "timestamp": 1692627052803,
     "user": {
      "displayName": "Kelly Butler",
      "userId": "08515498257456133265"
     },
     "user_tz": 240
    },
    "id": "FJPDKio3Xxzb",
    "outputId": "dfd49772-9604-4fd3-ce99-b57fc526aeae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 91166 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# Creating generator for 64 x 64 sized images\n",
    "columns = ['class_label_blouse', 'class_label_dhoti_pants',\n",
    "       'class_label_dupattas', 'class_label_gowns', 'class_label_kurta_men',\n",
    "       'class_label_leggings_and_salwars', 'class_label_lehenga',\n",
    "       'class_label_mojaris_men', 'class_label_mojaris_women',\n",
    "       'class_label_nehru_jackets', 'class_label_palazzos',\n",
    "       'class_label_petticoats', 'class_label_saree', 'class_label_sherwanis',\n",
    "       'class_label_women_kurta']\n",
    "train_datagen=ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_dataframe(dataframe=df_train, directory='/kaggle/input/indo-fashion-dataset', x_col='image_path', y_col=columns, target_size=(64,64), batch_size=32, seed=26, save_to_dir='/kaggle/working', class_mode='raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "965b52cf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-21T22:48:47.515517Z",
     "iopub.status.busy": "2023-08-21T22:48:47.515170Z",
     "iopub.status.idle": "2023-08-21T22:49:03.776791Z",
     "shell.execute_reply": "2023-08-21T22:49:03.775846Z",
     "shell.execute_reply.started": "2023-08-21T22:48:47.515484Z"
    },
    "executionInfo": {
     "elapsed": 418,
     "status": "ok",
     "timestamp": 1692627166048,
     "user": {
      "displayName": "Kelly Butler",
      "userId": "08515498257456133265"
     },
     "user_tz": 240
    },
    "id": "iMCAsrzPb67i",
    "outputId": "863fbf8f-08c1-4360-d2cb-2fd044f1ac9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7500 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "val_datagen=ImageDataGenerator(rescale=1./255)\n",
    "val_generator = val_datagen.flow_from_dataframe(dataframe=df_val, directory='/kaggle/input/indo-fashion-dataset', x_col='image_path', y_col=columns, target_size=(64,64), batch_size=32, seed=26, save_to_dir='/kaggle/working', class_mode='raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be73ba7",
   "metadata": {
    "id": "4bI6aiKIPlGR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4d338f2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-21T22:49:08.624878Z",
     "iopub.status.busy": "2023-08-21T22:49:08.624514Z",
     "iopub.status.idle": "2023-08-21T22:49:13.223156Z",
     "shell.execute_reply": "2023-08-21T22:49:13.222094Z",
     "shell.execute_reply.started": "2023-08-21T22:49:08.624848Z"
    },
    "executionInfo": {
     "elapsed": 573,
     "status": "ok",
     "timestamp": 1692629951064,
     "user": {
      "displayName": "Kelly Butler",
      "userId": "08515498257456133265"
     },
     "user_tz": 240
    },
    "id": "PsGLmgnLUSNX"
   },
   "outputs": [],
   "source": [
    "# Setting up model\n",
    "img_width, img_height = 64, 64\n",
    "\n",
    "train_data = train_generator\n",
    "val_data = val_generator\n",
    "nb_train_samples = 91166\n",
    "nb_validation_samples = 7500\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "\n",
    "input_shape = (img_width, img_height, 3)\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(15))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "32127d66",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2023-08-21T22:49:23.501158Z",
     "iopub.status.busy": "2023-08-21T22:49:23.500789Z",
     "iopub.status.idle": "2023-08-21T23:23:26.841363Z",
     "shell.execute_reply": "2023-08-21T23:23:26.836630Z",
     "shell.execute_reply.started": "2023-08-21T22:49:23.501127Z"
    },
    "executionInfo": {
     "elapsed": 35249,
     "status": "error",
     "timestamp": 1692629988242,
     "user": {
      "displayName": "Kelly Butler",
      "userId": "08515498257456133265"
     },
     "user_tz": 240
    },
    "id": "BaB7j4UvPlQ0",
    "outputId": "9a420f8b-0a34-4361-b44d-6df1e34fb08a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2849/2849 [==============================] - 221s 73ms/step - loss: 1.2183 - accuracy: 0.6116\n",
      "Epoch 2/10\n",
      "2849/2849 [==============================] - 191s 67ms/step - loss: 0.8781 - accuracy: 0.7171\n",
      "Epoch 3/10\n",
      "2849/2849 [==============================] - 195s 68ms/step - loss: 0.7809 - accuracy: 0.7487\n",
      "Epoch 4/10\n",
      "2849/2849 [==============================] - 198s 69ms/step - loss: 0.7188 - accuracy: 0.7681 - val_loss: 0.5665 - val_accuracy: 0.8021\n",
      "Epoch 5/10\n",
      "2849/2849 [==============================] - 198s 69ms/step - loss: 0.6755 - accuracy: 0.7809\n",
      "Epoch 6/10\n",
      "2849/2849 [==============================] - 200s 70ms/step - loss: 0.6419 - accuracy: 0.7899\n",
      "Epoch 7/10\n",
      "2849/2849 [==============================] - 198s 69ms/step - loss: 0.6160 - accuracy: 0.7993\n",
      "Epoch 8/10\n",
      "2849/2849 [==============================] - 200s 70ms/step - loss: 0.5875 - accuracy: 0.8066 - val_loss: 0.5409 - val_accuracy: 0.8646\n",
      "Epoch 9/10\n",
      "2849/2849 [==============================] - 196s 69ms/step - loss: 0.5702 - accuracy: 0.8119\n",
      "Epoch 10/10\n",
      "2849/2849 [==============================] - 198s 69ms/step - loss: 0.5505 - accuracy: 0.8174\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7d9ecb4ba380>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x=train_generator,\n",
    "    y=None,\n",
    "    validation_data=val_generator,\n",
    "    epochs=10,\n",
    "    verbose=\"auto\",\n",
    "    callbacks=None,\n",
    "    validation_split=0.0,\n",
    "    shuffle=True,\n",
    "    class_weight=None,\n",
    "    sample_weight=None,\n",
    "    initial_epoch=0,\n",
    "    steps_per_epoch=None,\n",
    "    validation_steps=3,\n",
    "    validation_batch_size=batch_size,\n",
    "    validation_freq=4,\n",
    "    max_queue_size=10,\n",
    "    use_multiprocessing=True,\n",
    "    workers=6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "80ce22dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-21T23:40:33.348040Z",
     "iopub.status.busy": "2023-08-21T23:40:33.347504Z",
     "iopub.status.idle": "2023-08-21T23:40:33.366815Z",
     "shell.execute_reply": "2023-08-21T23:40:33.365591Z",
     "shell.execute_reply.started": "2023-08-21T23:40:33.347996Z"
    },
    "id": "L3SN0hQ-PlDf"
   },
   "outputs": [],
   "source": [
    "inputs = model.input\n",
    "outputs = [model.layers[i].output for i in range(2,len(model.layers))]\n",
    "mod = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "daceab15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-22T00:46:39.566446Z",
     "iopub.status.busy": "2023-08-22T00:46:39.566165Z",
     "iopub.status.idle": "2023-08-22T00:46:39.571507Z",
     "shell.execute_reply": "2023-08-22T00:46:39.570509Z",
     "shell.execute_reply.started": "2023-08-22T00:46:39.566422Z"
    }
   },
   "outputs": [],
   "source": [
    "#image = imageio.imread('/kaggle/input/indo-fashion-dataset/images/train/60000.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12fcf8ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-22T00:46:39.579307Z",
     "iopub.status.busy": "2023-08-22T00:46:39.579039Z",
     "iopub.status.idle": "2023-08-22T00:46:39.583731Z",
     "shell.execute_reply": "2023-08-22T00:46:39.582666Z",
     "shell.execute_reply.started": "2023-08-22T00:46:39.579283Z"
    },
    "id": "iN_Fy5aDPk7w"
   },
   "outputs": [],
   "source": [
    "#all_layers_predictions = mod.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65db50d",
   "metadata": {
    "id": "_UXxsmH7PkvI"
   },
   "outputs": [],
   "source": [
    "image1_channel8_fromlayer10 = all_layers_predictions[10][1,:,:,8]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
