{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4ef7ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c079b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# most of code is from https://saturncloud.io/blog/how-to-handle-different-image-sizes-in-tensorflow-cnn-training/#:~:text=Solution%202%3A%20Use%20Variable%20Input,keras.\n",
    "# Thursday, July 06, 2023\n",
    "\n",
    "def resize_image(image, size=(256, 256)):\n",
    "    return tf.image.resize(image, size)\n",
    "\n",
    "for i in range(91167):\n",
    "dataset = dataset.map(lambda x: tf.io.read_file(x))\n",
    "dataset = dataset.map(lambda x: color.rgb2gray(x))\n",
    "dataset = dataset.map(lambda x: tf.image.decode_jpeg(x, channels=0))\n",
    "\n",
    "# Apply resizing to dataset\n",
    "dataset = dataset.map(lambda x: resize_image(x, size=(256, 256)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77342878",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'train_datagen'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_generator \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_datagen\u001b[49m\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/butler/Documents/hp/Retrieval_of_Indian_clothing/data/raw/indian_clothing/images\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m     target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m),\n\u001b[1;32m      4\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[1;32m      5\u001b[0m     class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'train_datagen'"
     ]
    }
   ],
   "source": [
    "train_generator = tf.train_datagen.flow_from_directory(\n",
    "    '/Users/butler/Documents/hp/Retrieval_of_Indian_clothing/data/raw/indian_clothing/images',\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac923e4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
